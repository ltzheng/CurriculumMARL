starcraft-8m-ppo:
  run: PPO
  checkpoint_freq: 100
  checkpoint_at_end: true
  local_dir: ray_results
  stop:
    timesteps_total: 1000000
  config:
    seed: 0
    framework: torch
    callbacks: PvEMetrics

    env: starcraft_pve
    env_config:
      map_name: 8m

    num_workers: 1
    num_cpus_for_driver: 1
    num_envs_per_worker: 1
    num_cpus_per_worker: 1
    num_gpus: 1
    num_gpus_per_worker: 0
    evaluation_num_workers: 1
    evaluation_interval: 5  # iterations
    evaluation_duration: 20
    evaluation_duration_unit: episodes
    evaluation_parallel_to_training: true
    disable_env_checking: true

    evaluation_config:
      env_config:
        map_name: 8m

    model:
      custom_model: action_mask_model

    multiagent:
      policies: ["shared_policy"]
      policy_mapping_fn: parameter_sharing
      policies_to_train: ["shared_policy"]
